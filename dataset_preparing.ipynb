{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset preparing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yxn-coder/covid19/blob/master/dataset_preparing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xivVKx_ifTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdc83f9-4c74-4f83-c953-2c98d24d77ea"
      },
      "source": [
        "!pip install zipfile36\n",
        "!pip install pydicom"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zipfile36\n",
            "  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6p_R7p6hxyG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random \n",
        "import shutil\n",
        "import pydicom as dicom\n",
        "import cv2\n",
        "import csv\n",
        "import zipfile"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzSbGa0UETOK"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfsCc6mxjHXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130db343-f1e5-4f99-e6b9-dfa93b2a4e54"
      },
      "source": [
        "# This is a link to kaggle dataset. If you have downloaded it already, save it as kaggle.zip in the current directory.\n",
        "# If the link expired, get the new link from https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data\n",
        "!wget -cO - 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/10338/862042/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1637062574&Signature=kiJ0NSzHPgHibazBnwLo2py%2Bw%2F%2FPnhc%2FYDrbI2eQ2SKCQGhT71y%2BwJxaH7wiq0sUGAVbJPkuCC3GTEJ42T3h0PNsHP8UzfDo15mb6%2Bb92B%2Fl%2F%2B60N0K%2FgEGRQ%2BB0bT1Ixa%2Fw5sCdUHmanztXH6n297UyHTdfe020oovxgX%2BkRX18Q1tmbEzJNln4IUHjNpsVMXP3X4Pgsg0a4LxGRGWfm06QIvN384UzYhimZWbNjirCS5n%2BVqhHGmS5BTM9o1F5v%2FZehVnlODlp55bCwl4lqmqYfbwj1ZdSkyvOnlVUInApdYSxfC3LQ5EYrb8C97asNYQc%2BXXpr2emFdkJha1%2BvQ%3D%3D&response-content-disposition=attachment%3B+filename%3Drsna-pneumonia-detection-challenge.zip' > kaggle.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-13 11:40:28--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/10338/862042/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1637062574&Signature=kiJ0NSzHPgHibazBnwLo2py%2Bw%2F%2FPnhc%2FYDrbI2eQ2SKCQGhT71y%2BwJxaH7wiq0sUGAVbJPkuCC3GTEJ42T3h0PNsHP8UzfDo15mb6%2Bb92B%2Fl%2F%2B60N0K%2FgEGRQ%2BB0bT1Ixa%2Fw5sCdUHmanztXH6n297UyHTdfe020oovxgX%2BkRX18Q1tmbEzJNln4IUHjNpsVMXP3X4Pgsg0a4LxGRGWfm06QIvN384UzYhimZWbNjirCS5n%2BVqhHGmS5BTM9o1F5v%2FZehVnlODlp55bCwl4lqmqYfbwj1ZdSkyvOnlVUInApdYSxfC3LQ5EYrb8C97asNYQc%2BXXpr2emFdkJha1%2BvQ%3D%3D&response-content-disposition=attachment%3B+filename%3Drsna-pneumonia-detection-challenge.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.125.128, 142.250.136.128, 142.250.152.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3932287530 (3.7G) [application/zip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   3.66G  24.6MB/s    in 64s     \n",
            "\n",
            "2021-11-13 11:41:31 (59.0 MB/s) - written to stdout [3932287530/3932287530]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY3c67BdjJf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731dc569-eb67-450a-be64-11a0c42a2842"
      },
      "source": [
        "#load covid-chestxray-dataset\n",
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'covid-chestxray-dataset'...\n",
            "remote: Enumerating objects: 3641, done.\u001b[K\n",
            "remote: Total 3641 (delta 0), reused 0 (delta 0), pack-reused 3641\u001b[K\n",
            "Receiving objects: 100% (3641/3641), 632.96 MiB | 39.34 MiB/s, done.\n",
            "Resolving deltas: 100% (1450/1450), done.\n",
            "Checking out files: 100% (1174/1174), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YgUxOytjd-y"
      },
      "source": [
        "archive = zipfile.ZipFile('kaggle.zip') #Extract Kaggle Dataset\n",
        "for file in archive.namelist():\n",
        "     archive.extract(file, '.')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY0hd3Osinu6"
      },
      "source": [
        "# Define addresses\n",
        "covid_chestxray = './covid-chestxray-dataset/metadata.csv'\n",
        "\n",
        "kaggle_csvname = 'stage_2_detailed_class_info.csv' # normal cases from kaggle dataset\n",
        "kaggle_csvname2 = 'stage_2_train_labels.csv' # pneumonia cases from kaggle dataset\n",
        "kaggle_imgpath = 'stage_2_train_images'\n",
        "\n",
        "related_views=[\"AP\",\"PA\",\"AP Supine\",\"AP semi erect\"]  #The view column in the covid_chestxray dataset that has suitable data\n",
        "filename_label = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
        "\n",
        "mapping = dict() #mapping the types of the suitable data in the covid-chestxray-dataset into 3 classes\n",
        "mapping['COVID-19'] = 'COVID-19'\n",
        "mapping['COVID-19, ARDS'] = 'COVID-19'\n",
        "mapping['Pneumocystis'] = 'pneumonia'\n",
        "mapping['SARS'] = 'pneumonia'\n",
        "mapping['Streptococcus'] = 'pneumonia'\n",
        "mapping['Normal'] = 'normal'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbSP6g3ekj6Z"
      },
      "source": [
        "# In the next two cells we create All.csv\n",
        "covid_csv = pd.read_csv(covid_chestxray)\n",
        "for index, row in covid_csv.iterrows():\n",
        "    if row['finding'] in mapping:\n",
        "        if row['view'] in related_views:\n",
        "            if row['filename'] not in filename_label[mapping[row['finding']]]:\n",
        "                filename_label[mapping[row['finding']]].append(row['filename']) #add the suitable images names in the covid-chestxray-dataset\n",
        "\n",
        "\n",
        "csv_normal = pd.read_csv(kaggle_csvname)\n",
        "csv_pneu = pd.read_csv(kaggle_csvname2)\n",
        "all_names=[]\n",
        "for index, row in csv_normal.iterrows():\n",
        "    if row['class'] == 'Normal':\n",
        "        if row['patientId'] not in all_names:\n",
        "            all_names.append(row['patientId'])\n",
        "            new_name=row['patientId']+'.dcm'\n",
        "            if new_name not in filename_label['normal']:\n",
        "                filename_label['normal'].append(new_name) #add the suitable normal cases names in the kaggle dataset\n",
        "        \n",
        "for index, row in csv_pneu.iterrows():\n",
        "    if int(row['Target']) == 1:\n",
        "        if row['patientId'] not in all_names:\n",
        "            all_names.append(row['patientId'])\n",
        "            new_name=row['patientId']+'.dcm'\n",
        "            if new_name not in filename_label['pneumonia']:\n",
        "                filename_label['pneumonia'].append(new_name) #add the suitable pneumonia cases names in the kaggle dataset\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UazllNTk2Zx"
      },
      "source": [
        "#Export All.csv\n",
        "with open('All.csv',newline='', mode='w') as csvfile:\n",
        "     csv_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "     csv_writer.writerow(['filename','class'])\n",
        "     for key in filename_label:\n",
        "         for row in filename_label[key]:\n",
        "             if '.dcm' in row:\n",
        "                 new_row=row[:-4]+'.png'\n",
        "                 csv_writer.writerow([new_row,key])\n",
        "             else:\n",
        "                 csv_writer.writerow([row,key])     "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQQ-6qhQom00"
      },
      "source": [
        "#We have divided patients infected to COVID-19 into five folds. This division is based on the covid-chestxray-dataset on 12 April\n",
        "#This dataset can change anytime, and you have to select the patients wisely\n",
        "ultimate_test_pneumonia = ['8', '31','171']\n",
        "ultimate_test_covid1  = ['19', '20', '36', '42', '86','13','96','51','49','116','150','151','168','56','70']\n",
        "ultimate_test_covid2=['2','4','6','11','12','13','14','15','117','152','163','167','142']\n",
        "ultimate_test_covid3=['16','17','18','21','33','34','36','37','44','45','46','47','165','166','164','161','160','132','162','159','158']\n",
        "ultimate_test_covid4=['39','40','41','43','44','45','46','47','48','50','51','52','157','156','155','154','153','151','149','148','147','146','145','71','72','73','74']\n",
        "ultimate_test_covid5=['53','56','57','58','59','60','61','62','63','64','65','66','67','68','69','118','132','139','138','141','144']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZWBHOoMo48X"
      },
      "source": [
        "try:\n",
        "  os.mkdir('Our_data_fold')\n",
        "  os.mkdir('Our_data_fold/fold1')\n",
        "  os.mkdir('Our_data_fold/fold2')\n",
        "  os.mkdir('Our_data_fold/fold3')\n",
        "  os.mkdir('Our_data_fold/fold4')\n",
        "  os.mkdir('Our_data_fold/fold5')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QX9VGIwo4_E"
      },
      "source": [
        "#In the next cell we create the 8 training phases for each fold"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enLJXGvKovgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc458475-4f44-419b-9bd0-0512aba9d869"
      },
      "source": [
        "for fo in range(1,6):\n",
        "\n",
        "    related_views=[\"AP\",\"PA\",\"AP Supine\",\"AP semi erect\"]\n",
        "    filename_label = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
        "    patients_id={'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
        "    covid_csv = pd.read_csv(covid_chestxray)\n",
        "    for index, row in covid_csv.iterrows():\n",
        "        if row['finding'] in mapping:\n",
        "            if row['view'] in related_views:\n",
        "                if row['filename'] not in filename_label[mapping[row['finding']]]:\n",
        "                    filename_label[mapping[row['finding']]].append(row['filename'])\n",
        "                    patients_id[mapping[row['finding']]].append(row['patientid'])\n",
        "\n",
        "\n",
        "    ultimate_train={'normal': [], 'pneumonia': [], 'COVID-19': []} #the data that is common between all training phases\n",
        "    ultimated_test=[] #The covid-19 and some pneumonia cases that is considered for testing in each fold\n",
        "    ultimate_test_pneumonia = ['8', '31','171'] #The pneumonia cases that are selected for testing\n",
        "    ultimate_test_covid  = globals()['ultimate_test_covid{}'.format(fo)].copy()\n",
        "    for index, row in covid_csv.iterrows(): #add the suitable images names in the covid-chestxray-dataset\n",
        "        if  str(row['patientid']) in ultimate_test_covid or str(row['patientid']) in ultimate_test_pneumonia:\n",
        "            if row['view'] in related_views:\n",
        "                if row['filename'] not in ultimated_test:\n",
        "                    ultimated_test.append(row['filename'])\n",
        "    for flp in filename_label['pneumonia']:\n",
        "        if flp not in ultimated_test:\n",
        "            ultimate_train['pneumonia'].append(flp)\n",
        "    for flp in filename_label['COVID-19']:\n",
        "        if flp not in ultimated_test:\n",
        "            ultimate_train['COVID-19'].append(flp)\n",
        "        \n",
        "    csv_normal = pd.read_csv(kaggle_csvname)\n",
        "    csv_pneu =   pd.read_csv(kaggle_csvname2)\n",
        "    patients = {'normal': [], 'pneumonia': []}\n",
        "    all_names=[]\n",
        "    all_data=[]\n",
        "    for index, row in csv_normal.iterrows(): #add the suitable normal cases in the kaggle dataset\n",
        "        if row['class'] == 'Normal':\n",
        "            if row['patientId'] not in all_names:\n",
        "                all_names.append(row['patientId'])\n",
        "                all_data.append([row['patientId'],'normal'])\n",
        "                patients['normal'].append(row['patientId'])\n",
        "                new_name=row['patientId']+'.dcm'\n",
        "                if new_name not in filename_label['normal']:\n",
        "                    filename_label['normal'].append(new_name)\n",
        "    for index, row in csv_pneu.iterrows(): #add the suitable pneumonia cases in the kaggle dataset\n",
        "        if int(row['Target']) == 1:\n",
        "            if row['patientId'] not in all_names:\n",
        "                all_names.append(row['patientId'])\n",
        "                all_data.append([row['patientId'],'pneumonia'])\n",
        "                patients['pneumonia'].append(row['patientId'])\n",
        "                new_name=row['patientId']+'.dcm'\n",
        "                if new_name not in filename_label['pneumonia']:\n",
        "                    filename_label['pneumonia'].append(new_name)\n",
        "                             \n",
        "    temp_all_train={'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
        "    for key in filename_label:\n",
        "        for fl in filename_label[key]:\n",
        "            if fl not in ultimated_test:\n",
        "                if fl not in ultimate_train[key]:\n",
        "                    temp_all_train[key].append(fl)    #the images that can be considered for training\n",
        "                    \n",
        "    for i in range(10):\n",
        "        for key in temp_all_train:\n",
        "            random.shuffle(temp_all_train[key])  #shuffle the training data\n",
        "    for i in range(1,9): # Choose data for each training phase\n",
        "        globals()['train{}'.format(i)]={'normal': [], 'pneumonia': ultimate_train['pneumonia'].copy(), 'COVID-19': ultimate_train['COVID-19'].copy()}\n",
        "        globals()['train{}'.format(i)]['normal'].extend(temp_all_train['normal'][250*i:(250*i)+250])\n",
        "        globals()['train{}'.format(i)]['pneumonia'].extend(temp_all_train['pneumonia'][200*i:(200*i)+200])\n",
        "\n",
        "    for i in range(1,9): #Export CSV\n",
        "        with open('Our_data_fold/fold{}/train{}.csv'.format(fo,i),newline='', mode='w') as csvfile:\n",
        "             all_rows=[]\n",
        "             csv_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "             csv_writer.writerow(['filename','class'])\n",
        "             for key in globals()['train{}'.format(i)]:\n",
        "                 for row in globals()['train{}'.format(i)][key]:\n",
        "                     if '.dcm' in row:\n",
        "                         new_row=row[:-4]+'.png'\n",
        "                         all_rows.append([new_row,key])\n",
        "                     else:\n",
        "                         if '.png ' in row:\n",
        "                             all_rows.append([row[:-1],key])\n",
        "                         else:\n",
        "                            all_rows.append([row,key])\n",
        "             for j in range(10):\n",
        "                random.shuffle(all_rows)\n",
        "             for arow in all_rows:\n",
        "                csv_writer.writerow(arow)\n",
        "    print('train list in fold{}'.format(fo),{'normal':len(globals()['train{}'.format(i)]['normal']),\n",
        "                                             'pneumonia':len(globals()['train{}'.format(i)]['pneumonia']),\n",
        "                                                             'COVID-19':len(globals()['train{}'.format(i)]['COVID-19'])})\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train list in fold5 {'normal': 250, 'pneumonia': 200, 'COVID-19': 0}\n"
          ]
        }
      ]
    }
  ]
}